import streamlit as st
import numpy as np
import tensorflow as tf
import cv2
from PIL import Image
import matplotlib.pyplot as plt
import os
import gdown

# ==== C·∫§U H√åNH ====
MODEL_ID = "1-qtMLem63El7msIK84PzMmMTvgyr9T1_"  # Google Drive file ID
MODEL_PATH = "hand_sign_cnn_model.h5"
IMG_SIZE = 224
#LABELS = sorted(os.listdir("./data"))  # C√πng th·ª© t·ª± nh∆∞ khi train
LABELS = [
    'A', 'B', 'C', 'D', 'del', 'E', 'F', 'G', 'H', 'I', 'J',
    'K', 'L', 'M', 'N', 'O', 'P', 'Q', 'R', 'S', 'T',
    'U', 'V', 'W', 'X', 'Y', 'Z', 'space'
]


# ==== T·∫¢I MODEL ====
@st.cache_resource
def load_model():
    if not os.path.exists(MODEL_PATH):
        gdown.download(id=MODEL_ID, output=MODEL_PATH, quiet=False)
    return tf.keras.models.load_model(MODEL_PATH)

# ==== TI·ªÄN X·ª¨ L√ù ·∫¢NH ====
def preprocess_image(img_bgr):
    img = cv2.cvtColor(img_bgr, cv2.COLOR_BGR2GRAY)

    # TƒÉng t∆∞∆°ng ph·∫£n
    clahe = cv2.createCLAHE(clipLimit=2.0, tileGridSize=(8, 8))
    img = clahe.apply(img)

    # L√†m n√©t
    sharp_kernel = np.array([[0, -1, 0], [-1, 5, -1], [0, -1, 0]])
    img = cv2.filter2D(img, -1, sharp_kernel)

    # Resize v√† chu·∫©n h√≥a
    img = cv2.resize(img, (IMG_SIZE, IMG_SIZE))
    img = img.astype(np.float32) / 255.0
    img = np.expand_dims(img, axis=(0, -1))  # shape: (1, 224, 224, 1)
    return img

# ==== GIAO DI·ªÜN ====
st.set_page_config(page_title="Nh·∫≠n di·ªán k√Ω hi·ªáu tay", layout="centered")

st.markdown("""
    <h1 style='text-align: center; color: #ff4b4b;'>ü§ü Nh·∫≠n di·ªán K√Ω hi·ªáu Tay b·∫±ng CNN</h1>
    <p style='text-align: center;'>T·∫£i l√™n ·∫£nh k√Ω hi·ªáu tay ƒë·ªÉ d·ª± ƒëo√°n ch·ªØ c√°i. ·ª®ng d·ª•ng s·ª≠ d·ª•ng TensorFlow + Streamlit Cloud.</p>
    """, unsafe_allow_html=True)

st.markdown("---")

uploaded_file = st.file_uploader("üì§ T·∫£i ·∫£nh k√Ω hi·ªáu tay (jpg, png)", type=["jpg", "jpeg", "png"])

# N√∫t th·ª≠ l·∫°i
if st.button("üîÅ L√†m m·ªõi"):
    st.experimental_rerun()

if uploaded_file:
    st.image(uploaded_file, caption="·∫¢nh b·∫°n ƒë√£ ch·ªçn", width=300)
    img = Image.open(uploaded_file).convert("RGB")
    img_np = np.array(img)
    img_bgr = cv2.cvtColor(img_np, cv2.COLOR_RGB2BGR)

    # Ti·ªÅn x·ª≠ l√Ω
    input_tensor = preprocess_image(img_bgr)

    # Load model v√† d·ª± ƒëo√°n
    model = load_model()
    prediction = model.predict(input_tensor)[0]
    pred_index = np.argmax(prediction)
    confidence = prediction[pred_index]

    # Hi·ªÉn th·ªã k·∫øt qu·∫£
    st.markdown(f"""
        <h2 style='text-align:center;'>
            üî§ D·ª± ƒëo√°n: <span style='color:#4CAF50'>{LABELS[pred_index]}</span> 
            (ƒê·ªô tin c·∫≠y: {confidence:.2f})
        </h2>
        """, unsafe_allow_html=True)

    # V·∫Ω bi·ªÉu ƒë·ªì
    fig, ax = plt.subplots(figsize=(12, 4))
    bars = ax.bar(LABELS, prediction, color='skyblue')
    bars[pred_index].set_color('green')
    ax.set_title("Ph√¢n b·ªë x√°c su·∫•t d·ª± ƒëo√°n", fontsize=14)
    ax.set_ylabel("X√°c su·∫•t")
    ax.set_xticks(np.arange(len(LABELS)))
    ax.set_xticklabels(LABELS, rotation=45)
    st.pyplot(fig)
